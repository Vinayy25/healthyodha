# ğŸ¯ HealthYoda Implementation Guide - Agents SDK with Tool Calling

## Executive Summary

You now have a **production-ready AI medical assistant** that uses the **OpenAI Agents SDK** for real-time voice conversations with **automatic tool calling** for dynamic RAG integration.

### What This Means

- âœ… **Voice I/O**: Patients speak, AI responds naturally
- âœ… **Tool Calling**: OpenAI automatically calls tools when needed
- âœ… **RAG Integration**: Medical frameworks retrieved dynamically
- âœ… **Evidence-Based**: Questions follow medical best practices
- âœ… **Summary Generation**: Professional reports auto-generated

---

## What Was Built

### Frontend (React + Agents SDK)

```typescript
// Two tools defined with Zod schemas:

1. get_relevant_questions
   - Triggered: When OpenAI needs medical guidance
   - Input: Patient symptom/complaint
   - Output: Medical framework from handbook
   - Effect: Shapes optimal follow-up questions

2. generate_medical_summary
   - Triggered: When conversation is complete
   - Input: Full conversation transcript
   - Output: Structured medical report
   - Effect: Provides actionable summary for doctors
```

### Backend (Node.js)

```javascript
// New endpoint for Agents SDK:
GET /client-secret
  Returns: Ephemeral WebRTC token

// Modified endpoints (now receive tool calls):
POST /rag        // RAG framework retrieval
POST /summary    // Medical report generation
```

### AWS RAG Service

```python
# Unchanged but now called dynamically:
POST /rag        // FAISS vector similarity search
                 // Returns medical frameworks
```

---

## Installation & Setup

### 1. Install Dependencies

```bash
cd /home/vinay/projects/freelance/healthyodha/frontend
npm install @openai/agents zod
```

### 2. Verify Services are Running

```bash
# Terminal 1 - RAG Service
cd /home/vinay/projects/freelance/healthyodha/rag_service
./start.sh
# Runs on: http://localhost:3000

# Terminal 2 - Backend
cd /home/vinay/projects/freelance/healthyodha/backend
./start.sh
# Runs on: http://localhost:3001

# Terminal 3 - Frontend
cd /home/vinay/projects/freelance/healthyodha/frontend
npm run dev
# Runs on: http://localhost:5173
```

### 3. Open Browser

```
http://localhost:5173
```

---

## How It Works (Step by Step)

### Initialization

1. User opens browser â†’ Clicks "Start Conversation"
2. Frontend calls `GET /client-secret` â†’ Gets ephemeral token
3. Frontend creates RealtimeAgent with two tools
4. Frontend creates RealtimeSession and connects

### Conversation Flow

```
1. User speaks: "I have chest pain"
   â†“
2. OpenAI Realtime API transcribes audio
   â†“
3. OpenAI recognizes: "I should call get_relevant_questions tool"
   â†“
4. Frontend tool executes:
   - Calls: POST /rag with {query: "chest pain"}
   - Backend queries AWS RAG service
   - Gets medical framework
   â†“
5. OpenAI receives framework and generates question:
   "Thank you. When did this chest pain start?"
   â†“
6. Frontend converts to speech and plays
   â†“
7. User responds â†’ Repeat from step 2
```

### Summary Generation

```
When OpenAI has gathered enough information:
   â†“
1. OpenAI calls: generateMedicalSummary tool
   â†“
2. Frontend tool executes:
   - Calls: POST /summary with conversation transcripts
   - Backend generates structured report using GPT-4o-mini
   â†“
3. Report displayed to doctor
   â†“
4. Doctor can copy summary or start new session
```

---

## Testing

### Test 1: Quick Connection Test

```bash
# Test backend is running
curl http://localhost:3001/client-secret

# Should return: {"client_secret":{"value":"...","expires_at":"..."}}
```

### Test 2: RAG Tool Test

```bash
# Test RAG endpoint
curl -X POST http://localhost:3001/rag \
  -H "Content-Type: application/json" \
  -d '{"query":"chest pain","k":2}'

# Should return: {"context":"...","sources":[...],"num_chunks":2}
```

### Test 3: Full Conversation Test

1. Open http://localhost:5173
2. Open browser console (F12)
3. Click "ğŸ™ï¸ Start Conversation"
4. Say: "I have chest pain"
5. Watch browser console for:
   ```
   ğŸ” Tool called: Retrieving questions for symptom: "I have chest pain"
   âœ… RAG Tool Response: 2 chunks from 2 sources
   ```
6. Listen for AI response
7. Verify AI asks about onset, quality, severity (from medical framework)

### Test 4: Summary Test

1. Continue conversation (5-10 exchanges)
2. Listen for: "I've gathered sufficient information"
3. Watch console for:
   ```
   ğŸ“ Tool called: Generating medical summary
   âœ… Medical summary generated
   ```
4. Summary appears on screen

---

## Key Files

| File                           | Purpose                                         |
| ------------------------------ | ----------------------------------------------- |
| `frontend/src/App.tsx`         | Complete Agents SDK implementation with 2 tools |
| `frontend/package.json`        | Added @openai/agents and zod dependencies       |
| `backend/server.js`            | Added /client-secret endpoint                   |
| `AGENTS_SDK_IMPLEMENTATION.md` | Comprehensive technical documentation           |
| `AGENTS_SDK_QUICK_START.md`    | Quick start guide                               |
| `rag_service/main.py`          | AWS RAG service (unchanged)                     |
| `rag_service/start.sh`         | RAG startup script                              |
| `backend/start.sh`             | Backend startup script                          |
| `frontend/start.sh`            | Frontend startup script                         |

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Browser   â”‚
â”‚  (React App)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ Tool 1: get_relevant_questions
         â”‚  â””â”€â†’ POST /rag â†’ Backend
         â”‚     â””â”€â†’ POST /rag â†’ AWS RAG Service
         â”‚        â””â”€â†’ Medical framework
         â”‚
         â”œâ”€ Tool 2: generate_medical_summary
         â”‚  â””â”€â†’ POST /summary â†’ Backend
         â”‚     â””â”€â†’ GPT-4o-mini
         â”‚        â””â”€â†’ Structured report
         â”‚
         â””â”€ Voice I/O (WebRTC)
            â””â”€â†’ OpenAI Realtime API
```

---

## Environment Variables

Currently using `.env` in project root:

```
OPENAI_API_KEY=sk-proj-...
RAG_SERVICE_URL=http://15.206.157.127:3000
PORT=3001
```

**Important**: RAG_SERVICE_URL points to your AWS RAG service (not localhost)

For local development with AWS RAG:

```
OPENAI_API_KEY=sk-proj-...
RAG_SERVICE_URL=http://15.206.157.127:3000
PORT=3001
```

For local development with local RAG:

```
OPENAI_API_KEY=sk-proj-...
RAG_SERVICE_URL=http://localhost:3000
PORT=3001
```

---

## Setup for AWS Deployment

### .env Configuration

```
OPENAI_API_KEY=sk-proj-...
RAG_SERVICE_URL=http://15.206.157.127:3000
PORT=3001
```

### Backend Behavior

- Backend runs locally (or on EC2)
- Backend forwards `/rag` calls to RAG_SERVICE_URL
- RAG service runs on AWS/EC2 (http://15.206.157.127:3000)
- Tool calls go: Frontend â†’ Backend â†’ AWS RAG Service

### What's Running Where

```
Local Machine:
  - Frontend: http://localhost:5173
  - Backend: http://localhost:3001

AWS/EC2 Server:
  - RAG Service: http://15.206.157.127:3000
  - Frontend (optional): http://15.206.157.127:5173
```

---

## Deployment to EC2

### Build Frontend

```bash
cd frontend
npm run build
```

### Copy to EC2

```bash
scp -i /path/to/mahe-server.pem \
  -r dist/* \
  ubuntu@15.206.157.127:~/healthyodha/frontend/
```

### Update API URLs

In `frontend/src/App.tsx`, change:

```typescript
// Change this:
"http://localhost:3001/client-secret";

// To this:
"http://15.206.157.127:3001/client-secret";
```

### Start on EC2

```bash
ssh -i mahe-server.pem ubuntu@15.206.157.127
cd healthyodha
./start-all.sh
```

### Access

```
Frontend: http://15.206.157.127:5173
RAG API: http://15.206.157.127:3000 (public)
```

---

## Console Output Guide

### Expected Logs During Startup

```
ğŸ“¡ Initializing HealthYoda Voice Agent with tools...
ğŸ”‘ Requesting ephemeral token from backend...
ğŸ¯ Connecting to Realtime API...
ğŸ¤ Requesting microphone access...
âœ… Microphone access granted
âœ… Session connected and ready
```

### Expected Logs During Conversation

```
ğŸ“ Transcription: I have chest pain
ğŸ” Tool called: Retrieving questions for symptom: "I have chest pain"
âœ… RAG Tool Response: 2 chunks from 2 sources
ğŸ”Š Received audio chunk
ğŸ“ Transcription: When did this start...
```

### Expected Logs During Summary

```
ğŸ“ Tool called: Generating medical summary
âœ… Medical summary generated
ğŸ“‹ Medical Summary Report displayed
```

---

## Troubleshooting

### Issue: "Connection refused" error

**Solution**: Ensure services are reachable

```bash
# Test backend
curl http://localhost:3001/client-secret

# Test AWS RAG (from backend machine)
# Backend should be able to reach: $RAG_SERVICE_URL/health
```

### Issue: Tool not executing / "Failed to retrieve medical framework"

**Solution**: Check RAG_SERVICE_URL configuration

```bash
# Verify .env has correct RAG_SERVICE_URL
cat .env | grep RAG_SERVICE_URL

# Test RAG service is accessible from backend machine
# If RAG is on AWS, ensure:
# 1. AWS security group allows port 3000
# 2. Backend can reach AWS IP
# 3. RAG_SERVICE_URL in .env is correct
```

### Issue: RAG returns empty or wrong data

**Solution**:

- Check handbook.txt has medical data
- Verify RAG service is running on AWS
- Check RAG service logs on AWS

---

## Performance Considerations

### Tool Call Latency (with AWS RAG)

- Backend to AWS RAG roundtrip: ~500-1000ms
- Total conversation latency: ~4-6 seconds (includes audio delays)

### Optimization Tips

- Keep RAG queries focused (currently k=2)
- Ensure AWS and backend have good network connection
- Use VPC if both on AWS for faster communication
- Monitor AWS bandwidth usage

---

## Next Steps

1. **Test Locally**: Follow testing section above
2. **Deploy to EC2**: Use deployment guide
3. **Monitor**: Watch console logs and backend logs
4. **Iterate**: Improve medical framework in handbook.txt
5. **Scale**: Add more medical conditions/frameworks

---

## Documentation References

- **Quick Start**: `AGENTS_SDK_QUICK_START.md`
- **Full Documentation**: `AGENTS_SDK_IMPLEMENTATION.md`
- **Frontend Code**: `frontend/src/App.tsx`
- **Backend Code**: `backend/server.js`

---

## Support & Debugging

### Enable Full Logging

Add to frontend App.tsx:

```typescript
// Uncomment for verbose logging
console.debug = console.log;
```

### Check Backend Logs

```bash
tail -f /tmp/backend.log | grep -E "Tool|RAG|Summary"
```

### Check RAG Service Logs

```bash
tail -f ~/healthyodha/rag_service/rag_service.log
```

---

## Success Criteria

âœ… Frontend loads without errors  
âœ… Browser requests microphone permission  
âœ… Tool calls visible in console  
âœ… Medical framework retrieved from RAG  
âœ… AI asks evidence-based questions  
âœ… Summary generated automatically  
âœ… Report displays to doctor

---

## Final Notes

This implementation uses:

- **OpenAI Agents SDK**: Official SDK for voice agents
- **Zod**: Type-safe schema validation for tools
- **Realtime API**: Latest voice capabilities
- **Tool Calling**: Dynamic knowledge retrieval
- **Medical Framework**: Evidence-based questioning

**You have a production-ready medical assistant!** ğŸš€

---

Generated: October 25, 2025  
Last Updated: Implementation Complete  
Status: âœ… Ready for Deployment
